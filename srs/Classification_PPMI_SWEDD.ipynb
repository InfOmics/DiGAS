{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "import subprocess\n",
    "import random\n",
    "import statistics\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData():\n",
    "    folder = '/Users/guglielmo/Desktop/Entropy/DataSet/PPMI'\n",
    "    \n",
    "    SnpToGene = pd.read_csv(os.path.join(folder, \"SnpToGene_RSID.txt\"), sep=\"\\t\", \n",
    "                            usecols = ['Genes','SNPsNamesConverter'])\n",
    "    coreGenes = pd.read_csv(os.path.join(folder,\"EmpiricPvalue_3_classes_1000/Intragenic_log_0.5.txt\"), \n",
    "                            header=None, sep=\" \")\n",
    "    coreGenes['class'] = coreGenes[0]+\"_\"+coreGenes[1]\n",
    "    coreGenes = coreGenes[coreGenes['class'] != 'PD_SWEDD'] # 2.5 class hills\n",
    "    coreGenes = list(set(coreGenes[2]))\n",
    "    SnpToGene = SnpToGene[SnpToGene['Genes'].isin(coreGenes)]\n",
    "    snps = SnpToGene['SNPsNamesConverter']\n",
    "    snps = snps.str.split(\",\").values\n",
    "    snps = np.concatenate(snps)\n",
    "    snps = np.char.lstrip(snps)\n",
    "    \n",
    "    res_folder = folder+'/Classification/Classification_2.5/'\n",
    "    \n",
    "    !mkdir {res_folder}\n",
    "    \n",
    "    path = os.path.join(res_folder, \"snps.txt\")\n",
    "    file = open(path, \"w+\")\n",
    "    for i in snps.tolist():\n",
    "        file.write(i+\"\\n\")\n",
    "    file.close()\n",
    "    \n",
    "    !plink --bfile {os.path.join(res_folder,\"PPMI\")} --extract {path} --make-bed --out {os.path.join(res_folder, \"Core\")}\n",
    "    !plink --bfile {os.path.join(res_folder, \"Core\")} --recodeA --out {os.path.join(res_folder, \"Core_recoded\")}\n",
    "    \n",
    "    recoded = pd.read_csv(os.path.join(folder,\"Classification/Classification_2.5/Core_recoded.raw\"),sep=\" \")\n",
    "    recoded = recoded.drop([\"FID\", \"PAT\",\"MAT\",\"SEX\",\"PHENOTYPE\"], axis = 1)\n",
    "\n",
    "    \n",
    "    pheno = pd.read_csv(os.path.join(folder,\"Subjects/PPMI_WHITE_INFO.csv\"),header=None)\n",
    "    pheno = pheno.drop([1,2], axis = 1)\n",
    "    pheno.columns = ['IID', 'Group']\n",
    "    for i in range(pheno.shape[0]):\n",
    "        if(pheno.at[i,'Group'] == 'SWEDD'):\n",
    "            pheno.at[i,'Group'] = 'PD'\n",
    "    merged = recoded.merge(pheno, on=\"IID\")    \n",
    "    data = merged.drop([\"IID\",\"Group\"], axis = 1)\n",
    "    data.fillna(data.median(), inplace=True)\n",
    "    remove = data.columns[data.isna().any()].tolist()\n",
    "    data.drop(remove, axis = 1, inplace=True)\n",
    "    data = data.replace(2,1)\n",
    "   \n",
    "    return data, merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo(s, X_train, X_test, y_train, y_test, k):\n",
    "    if(s == 'SVM_LINEAR'): clf = svm.SVC(kernel='linear')\n",
    "    elif(s == 'SVM_POLY'): clf = svm.SVC(kernel='poly')\n",
    "    elif(s == 'LDA'):      clf = LDA(n_components=1)\n",
    "    elif(s == 'DT'):       clf = DecisionTreeClassifier()\n",
    "    elif(s == 'KNN'):      clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    else: print('ERROR !!!!')\n",
    "        \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestk(x_train, x_test, y_train, y_test):\n",
    "    k=10\n",
    "    acc_array=np.zeros(k)\n",
    "\n",
    "    for k in np.arange(1,k+1,1): # here k will take values from 1 to 10\n",
    "        classifier = KNeighborsClassifier(n_neighbors=k).fit(x_train, y_train) # k changes after each iteration\n",
    "        y_pred = classifier.predict(x_test)\n",
    "        acc_tmp = metrics.accuracy_score(y_test, y_pred)\n",
    "        acc_array[k-1]=acc_tmp # store correctly the results\n",
    "\n",
    "    max_acc=np.amax(acc_array)\n",
    "    acc_list=list(acc_array)\n",
    "    k = acc_list.index(max_acc)\n",
    "    \n",
    "    return (k+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_results(d_test, d_pred, pos=\"PD\", neg=\"HC\"):\n",
    "    d_test = d_test.tolist()\n",
    "    d_pred = d_pred.tolist()\n",
    "    \n",
    "    tp = tn = fp = fn = 0 \n",
    "    \n",
    "    \n",
    "    for i in range(len(d_test)):\n",
    "        if d_test[i] == pos:\n",
    "            if d_test[i] == d_pred[i]:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        else:\n",
    "            if d_test[i] == d_pred[i]:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "    \n",
    "    if(tp+tn+fp+fn == 0): \n",
    "        accuracy=0\n",
    "    else:\n",
    "        accuracy = (tp + tn) / (tp+tn+fp+fn)\n",
    "        \n",
    "    if(tp + fp == 0):\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = tp / (tp + fp)\n",
    "        \n",
    "    if(tp + fn == 0):\n",
    "        recall = 0\n",
    "    else:\n",
    "         recall = tp / (tp + fn)\n",
    "        \n",
    "    if(precision == recall == 0):\n",
    "        f1score = 0\n",
    "    else:\n",
    "        f1score = 2 * ( (precision*recall) / (precision + recall) )\n",
    "            \n",
    "    \n",
    "    return tp, tn, fp, fn, accuracy, precision, recall, f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: /Users/guglielmo/Desktop/Entropy/DataSet/PPMI/Classification/Classification_2.5/: File exists\n",
      "PLINK v1.90b6.12 64-bit (28 Oct 2019)          www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2019 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to /Users/guglielmo/Desktop/Entropy/DataSet/PPMI/Classification/Classification_2.5/Core.log.\n",
      "Options in effect:\n",
      "  --bfile /Users/guglielmo/Desktop/Entropy/DataSet/PPMI/Classification/Classification_2.5/PPMI\n",
      "  --extract /Users/guglielmo/Desktop/Entropy/DataSet/PPMI/Classification/Classification_2.5/snps.txt\n",
      "  --make-bed\n",
      "  --out /Users/guglielmo/Desktop/Entropy/DataSet/PPMI/Classification/Classification_2.5/Core\n",
      "\n",
      "32768 MB RAM detected; reserving 16384 MB for main workspace.\n",
      "457171 variants loaded from .bim file.\n",
      "520 people (341 males, 179 females) loaded from .fam.\n",
      "--extract: 6271 variants remaining.\n",
      "Warning: At least 72 duplicate IDs in --extract file.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 520 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Warning: 704 het. haploid genotypes present (see\n",
      "/Users/guglielmo/Desktop/Entropy/DataSet/PPMI/Classification/Classification_2.5/Core.hh\n",
      "); many commands treat these as missing.\n",
      "Warning: Nonmissing nonmale Y chromosome genotype(s) present; many commands\n",
      "treat these as missing.\n",
      "Total genotyping rate is 0.962058.\n",
      "6271 variants and 520 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "--make-bed to\n",
      "/Users/guglielmo/Desktop/Entropy/DataSet/PPMI/Classification/Classification_2.5/Core.bed\n",
      "+\n",
      "/Users/guglielmo/Desktop/Entropy/DataSet/PPMI/Classification/Classification_2.5/Core.bim\n",
      "+\n",
      "/Users/guglielmo/Desktop/Entropy/DataSet/PPMI/Classification/Classification_2.5/Core.fam\n",
      "... 101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899done.\n",
      "PLINK v1.90b6.12 64-bit (28 Oct 2019)          www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2019 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Note: --recodeA flag deprecated.  Use \"--recode A ...\".\n",
      "Logging to /Users/guglielmo/Desktop/Entropy/DataSet/PPMI/Classification/Classification_2.5/Core_recoded.log.\n",
      "Options in effect:\n",
      "  --bfile /Users/guglielmo/Desktop/Entropy/DataSet/PPMI/Classification/Classification_2.5/Core\n",
      "  --out /Users/guglielmo/Desktop/Entropy/DataSet/PPMI/Classification/Classification_2.5/Core_recoded\n",
      "  --recode A\n",
      "\n",
      "32768 MB RAM detected; reserving 16384 MB for main workspace.\n",
      "6271 variants loaded from .bim file.\n",
      "520 people (341 males, 179 females) loaded from .fam.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 520 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Warning: 704 het. haploid genotypes present (see\n",
      "/Users/guglielmo/Desktop/Entropy/DataSet/PPMI/Classification/Classification_2.5/Core_recoded.hh\n",
      "); many commands treat these as missing.\n",
      "Warning: Nonmissing nonmale Y chromosome genotype(s) present; many commands\n",
      "treat these as missing.\n",
      "Total genotyping rate is 0.962058.\n",
      "6271 variants and 520 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "--recode A to\n",
      "/Users/guglielmo/Desktop/Entropy/DataSet/PPMI/Classification/Classification_2.5/Core_recoded.raw\n",
      "... 101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899done.\n",
      "\u001b[1m\u001b[92m###############################################  METHOD: SVM_LINEAR  ###############################################\u001b[0m\n",
      "****HC****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.8651 0.0232 - F1: 0.7466 0.0474 - Precision: 0.8028 0.0545 - Recall: 0.7015 0.0653\n",
      "\n",
      "****PD****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.8651 0.0232 - F1: 0.9079 0.0157 - Precision: 0.8873 0.0216 - Recall: 0.9302 0.0232\n",
      "\n",
      "****Confusion Matrix****\n",
      "# HC PD All\n",
      "HC 28.76(2.678) 12.24(2.678) 41(0.0) \n",
      "PD 7.19(2.39) 95.81(2.39) 103(0.0) \n",
      "All 35.95(3.825) 108.05(3.825) 144(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "****HC****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.8706 0.0422 - F1: 0.763 0.0812 - Precision: 0.8186 0.0893 - Recall: 0.7243 0.1131\n",
      "\n",
      "****PD****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.8706 0.0422 - F1: 0.9107 0.029 - Precision: 0.893 0.0405 - Recall: 0.9309 0.0391\n",
      "\n",
      "****Confusion Matrix****\n",
      "# HC PD All\n",
      "HC 10.14(1.583) 3.86(1.583) 14(0.0) \n",
      "PD 2.35(1.329) 31.65(1.329) 34(0.0) \n",
      "All 12.49(2.106) 35.51(2.106) 48(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m\u001b[92m###############################################  METHOD: SVM_POLY  ###############################################\u001b[0m\n",
      "****HC****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.7973 0.0183 - F1: 0.4642 0.0692 - Precision: 0.9321 0.0677 - Recall: 0.312 0.0591\n",
      "\n",
      "****PD****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.7973 0.0183 - F1: 0.8749 0.0104 - Precision: 0.7836 0.0147 - Recall: 0.9905 0.0097\n",
      "\n",
      "****Confusion Matrix****\n",
      "# HC PD All\n",
      "HC 12.79(2.422) 28.21(2.422) 41(0.0) \n",
      "PD 0.98(0.995) 102.02(0.995) 103(0.0) \n",
      "All 13.77(2.597) 130.23(2.597) 144(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "****HC****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.816 0.0396 - F1: 0.561 0.1263 - Precision: 0.902 0.1121 - Recall: 0.4207 0.13\n",
      "\n",
      "****PD****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.816 0.0396 - F1: 0.8832 0.0235 - Precision: 0.8056 0.0358 - Recall: 0.9788 0.0248\n",
      "\n",
      "****Confusion Matrix****\n",
      "# HC PD All\n",
      "HC 5.89(1.82) 8.11(1.82) 14(0.0) \n",
      "PD 0.72(0.842) 33.28(0.842) 34(0.0) \n",
      "All 6.61(2.103) 41.39(2.103) 48(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m\u001b[92m###############################################  METHOD: LDA  ###############################################\u001b[0m\n",
      "****HC****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.7926 0.0229 - F1: 0.4919 0.0831 - Precision: 0.8085 0.0843 - Recall: 0.3595 0.0818\n",
      "\n",
      "****PD****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.7926 0.0229 - F1: 0.8695 0.0133 - Precision: 0.7916 0.0204 - Recall: 0.965 0.018\n",
      "\n",
      "****Confusion Matrix****\n",
      "# HC PD All\n",
      "HC 14.74(3.353) 26.26(3.353) 41(0.0) \n",
      "PD 3.6(1.853) 99.4(1.853) 103(0.0) \n",
      "All 18.34(4.295) 125.66(4.295) 144(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "****HC****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.8123 0.0451 - F1: 0.5867 0.1342 - Precision: 0.7989 0.1512 - Recall: 0.4771 0.1414\n",
      "\n",
      "****PD****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.8123 0.0451 - F1: 0.8779 0.0277 - Precision: 0.8173 0.0403 - Recall: 0.9503 0.0364\n",
      "\n",
      "****Confusion Matrix****\n",
      "# HC PD All\n",
      "HC 6.747(1.87) 7.32(1.979) 14(0.0) \n",
      "PD 1.707(1.231) 32.31(1.237) 34(0.0) \n",
      "All 8.455(2.357) 39.63(2.493) 48(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m\u001b[92m###############################################  METHOD: DT  ###############################################\u001b[0m\n",
      "****HC****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.6388 0.0339 - F1: 0.3381 0.0608 - Precision: 0.3553 0.0616 - Recall: 0.3263 0.0708\n",
      "\n",
      "****PD****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.6388 0.0339 - F1: 0.751 0.0268 - Precision: 0.7402 0.0214 - Recall: 0.7632 0.0437\n",
      "\n",
      "****Confusion Matrix****\n",
      "# HC PD All\n",
      "HC 13.38(2.902) 27.62(2.902) 41(0.0) \n",
      "PD 24.39(4.497) 78.61(4.497) 103(0.0) \n",
      "All 37.77(5.785) 106.23(5.785) 144(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****HC****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.6206 0.0644 - F1: 0.3288 0.1006 - Precision: 0.3455 0.1076 - Recall: 0.3214 0.1091\n",
      "\n",
      "****PD****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.6206 0.0644 - F1: 0.7338 0.0525 - Precision: 0.7267 0.0394 - Recall: 0.7438 0.0776\n",
      "\n",
      "****Confusion Matrix****\n",
      "# HC PD All\n",
      "HC 4.5(1.528) 9.5(1.528) 14(0.0) \n",
      "PD 8.71(2.637) 25.29(2.637) 34(0.0) \n",
      "All 13.21(3.006) 34.79(3.006) 48(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m\u001b[92m###############################################  METHOD: KNN  ###############################################\u001b[0m\n",
      "****HC****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.7449 0.0334 - F1: 0.5062 0.0667 - Precision: 0.5667 0.0741 - Recall: 0.4617 0.0755\n",
      "\n",
      "****PD****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.7449 0.0334 - F1: 0.8277 0.0237 - Precision: 0.8005 0.0235 - Recall: 0.8577 0.0359\n",
      "\n",
      "****Confusion Matrix****\n",
      "# HC PD All\n",
      "HC 18.93(3.095) 22.07(3.095) 41(0.0) \n",
      "PD 14.66(3.699) 88.34(3.699) 103(0.0) \n",
      "All 33.59(4.839) 110.41(4.839) 144(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "****HC****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.7477 0.06 - F1: 0.5136 0.1231 - Precision: 0.5916 0.1331 - Recall: 0.4657 0.1356\n",
      "\n",
      "****PD****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.7477 0.06 - F1: 0.8287 0.0422 - Precision: 0.7984 0.0437 - Recall: 0.8638 0.0604\n",
      "\n",
      "****Confusion Matrix****\n",
      "# HC PD All\n",
      "HC 6.52(1.899) 7.48(1.899) 14(0.0) \n",
      "PD 4.63(2.053) 29.37(2.053) 34(0.0) \n",
      "All 11.15(2.713) 36.85(2.713) 48(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "[data, merged] = getData()\n",
    "column_names   = [\"Method\", \"Accuracy\", \"F1\", \"Precision\", \"Recall\", \"TrainSize\"]\n",
    "df = pd.DataFrame(columns = column_names)\n",
    "for method in ['SVM_LINEAR','SVM_POLY','LDA','DT','KNN']: \n",
    "    print(bcolors.BOLD + bcolors.OKGREEN + '#' * 47 + \"  METHOD: \" + method + '  ' + '#' * 47 + bcolors.ENDC)\n",
    "    for s in [0.3, 0.1]:\n",
    "        acc = list()\n",
    "        f1  = list()\n",
    "        precision = list()\n",
    "        recall    = list()\n",
    "\n",
    "        v_acc = list()\n",
    "        v_f1  = list()\n",
    "        v_precision = list()\n",
    "        v_recall    = list()\n",
    "\n",
    "        v_acc_cn = list()\n",
    "        v_f1_cn  = list()\n",
    "        v_precision_cn = list()\n",
    "        v_recall_cn    = list()\n",
    "\n",
    "        conf_mat = dict()\n",
    "\n",
    "        flag = True \n",
    "        k = 5\n",
    "\n",
    "        for i in range(1, 101):\n",
    "            rand = i \n",
    "            X_train, X_test, y_train, y_test = train_test_split(data, merged['Group'], test_size=s, \n",
    "                                                                random_state=rand, stratify=merged['Group'])\n",
    "            if(method=='KNN' and flag):\n",
    "                    k = bestk(X_train, X_test, y_train, y_test)\n",
    "                    flag = False\n",
    "\n",
    "            clf = algo(method, X_train, X_test, y_train, y_test, k)\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "            dd_pred = [ 0 if x == 'HC' else 1 for x in y_pred.tolist()]\n",
    "            dd_test = [ 0 if x == 'HC' else 1 for x in y_test.tolist()]\n",
    "\n",
    "            acc.append(metrics.accuracy_score(dd_test, dd_pred))\n",
    "            f1.append(metrics.f1_score(dd_test, dd_pred))\n",
    "            precision.append(metrics.precision_score(dd_test, dd_pred))\n",
    "            recall.append(metrics.recall_score(dd_test, dd_pred))\n",
    "\n",
    "\n",
    "            v_tp, v_tn, v_fp, v_fn, v_a, v_p, v_r, v_f = classification_results(y_test, y_pred)\n",
    "            v_acc.append(v_a)\n",
    "            v_f1.append(v_f)\n",
    "            v_precision.append(v_p)\n",
    "            v_recall.append(v_r)\n",
    "\n",
    "            v_tp, v_tn, v_fp, v_fn, v_a, v_p, v_r, v_f = classification_results(y_test,y_pred, pos='HC', neg='PD')\n",
    "            v_acc_cn.append(v_a)\n",
    "            v_f1_cn.append(v_f)\n",
    "            v_precision_cn.append(v_p)\n",
    "            v_recall_cn.append(v_r)\n",
    "\n",
    "            df_confusion = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "            for c in df_confusion.columns:\n",
    "                for r in df_confusion.index:\n",
    "                    cr = (c,r)\n",
    "                    if cr not in conf_mat:\n",
    "                        conf_mat[cr] = list()\n",
    "                    conf_mat[cr].append( int(df_confusion.at[r,c]) )\n",
    "\n",
    "        print(\"****HC****\")\n",
    "        print(bcolors.BOLD + bcolors.WARNING +\"Train \"+ str((1-s)*100) + \"%\" +\"- Test \" + str(s*100) + \"%\" +bcolors.ENDC +\n",
    "              \" - Accuracy: \"  + str(round(statistics.mean(v_acc_cn), 4)) +\" \"+str(round(statistics.stdev(v_acc_cn), 4))+\n",
    "              \" - F1: \"        + str(round(statistics.mean(v_f1_cn), 4)) + \" \"+str(round(statistics.stdev(v_f1_cn), 4))+\n",
    "              \" - Precision: \" + str(round(statistics.mean(v_precision_cn), 4)) + \" \"+str(round(statistics.stdev(v_precision_cn), 4))+\n",
    "              \" - Recall: \"    + str(round(statistics.mean(v_recall_cn), 4)) +\" \"+str(round(statistics.stdev(v_recall_cn), 4)))\n",
    "        print()\n",
    "\n",
    "        print(\"****PD****\")\n",
    "        print(bcolors.BOLD + bcolors.WARNING +\"Train \"+ str((1-s)*100) + \"%\" +\"- Test \" + str(s*100) + \"%\" +bcolors.ENDC +\n",
    "              \" - Accuracy: \"  + str(round(statistics.mean(v_acc), 4)) + \" \"+str(round(statistics.stdev(v_acc), 4))+\n",
    "              \" - F1: \"        + str(round(statistics.mean(v_f1), 4)) + \" \"+str(round(statistics.stdev(v_f1), 4))+\n",
    "              \" - Precision: \" + str(round(statistics.mean(v_precision), 4)) + \" \"+str(round(statistics.stdev(v_precision), 4))+\n",
    "              \" - Recall: \"    + str(round(statistics.mean(v_recall), 4)) +\" \"+str(round(statistics.stdev(v_recall), 4)))\n",
    "        print()\n",
    "\n",
    "        '''\n",
    "        print(\"****MEAN(AD,CN)****\")\n",
    "        print(\"Train \"+ str((1-s)*100) + \"%\" +\" - Test \" + str(s*100) + \"%\" + \n",
    "              \" - V Accuracy: \"  + str(round(statistics.mean([statistics.mean(v_acc),statistics.mean(v_acc_cn)]), 4)) +\n",
    "              \" - V F1: \"        + str(round(statistics.mean([statistics.mean(v_f1),statistics.mean(v_f1_cn)]), 4)) +\n",
    "              \" - V Precision: \" + str(round(statistics.mean([statistics.mean(v_precision),statistics.mean(v_precision_cn)]), 4)) +\n",
    "              \" - V Recall: \"    + str(round(statistics.mean([statistics.mean(v_recall),statistics.mean(v_recall_cn)]), 4)))\n",
    "        print()\n",
    "        '''\n",
    "\n",
    "        print(\"****Confusion Matrix****\")\n",
    "        print(\"# \"+ \" \".join(list(df_confusion.columns)))\n",
    "\n",
    "        for r in df_confusion.index:\n",
    "            print(r+\" \",end=\"\")\n",
    "            for c in df_confusion.columns:\n",
    "                print( str(round(statistics.mean(conf_mat[(c,r)]),3)) + \n",
    "                      \"(\" + str(round(statistics.stdev(conf_mat[(c,r)]),3)) + \") \" , end=\"\" )\n",
    "            print()\n",
    "        print('-' * 115)\n",
    "        \n",
    "\n",
    "        acc_plot = round(statistics.mean([statistics.mean(v_acc),statistics.mean(v_acc_cn)]), 4)\n",
    "        f1_plot  = round(statistics.mean([statistics.mean(v_f1),statistics.mean(v_f1_cn)]), 4)\n",
    "        precision_plot = round(statistics.mean([statistics.mean(v_precision),statistics.mean(v_precision_cn)]), 4)\n",
    "        recall_plot = round(statistics.mean([statistics.mean(v_recall),statistics.mean(v_recall_cn)]), 4)\n",
    "\n",
    "        df = df.append({\"Method\":method, \"Accuracy\":acc_plot, \"F1\":f1_plot, \"Precision\":precision_plot, \n",
    "                        \"Recall\":recall_plot, \"TrainSize\":int((1-s)*100)}, ignore_index=True)\n",
    "\n",
    "df.to_csv(\"../PLOT/PPMI_SWEDD_res.csv\", header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
