{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "import subprocess\n",
    "import random\n",
    "import statistics\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(adni):\n",
    "    folder = os.path.join('/Users/guglielmo/Desktop/Entropy/DataSet', adni)\n",
    "    \n",
    "    SnpToGene = pd.read_csv(os.path.join(folder, \"SnpToGene_RSID.txt\"), sep=\"\\t\", \n",
    "                            usecols = ['Genes','SNPsNamesConverter'])\n",
    "    coreGenes = pd.read_csv(os.path.join(folder,\"EmpiricPvalue_3_classes_1000/Intragenic_log_0.5.txt\"), \n",
    "                            header=None, sep=\" \")\n",
    "    coreGenes['class'] = coreGenes[0]+\"_\"+coreGenes[1]\n",
    "    coreGenes = coreGenes[coreGenes['class'] != 'AD_MCI'] # 2.5 class hills\n",
    "    coreGenes = list(set(coreGenes[2]))\n",
    "    SnpToGene = SnpToGene[SnpToGene['Genes'].isin(coreGenes)]\n",
    "    snps = SnpToGene['SNPsNamesConverter']\n",
    "    snps = snps.str.split(\",\").values\n",
    "    snps = np.concatenate(snps)\n",
    "    snps = np.char.lstrip(snps)\n",
    "    \n",
    "    res_folder = folder+'/Classification/Classification_2.5/'\n",
    "    \n",
    "    !mkdir {res_folder}\n",
    "    \n",
    "    path = os.path.join(res_folder, \"snps.txt\")\n",
    "    file = open(path, \"w+\")\n",
    "    for i in snps.tolist():\n",
    "        file.write(i+\"\\n\")\n",
    "    file.close()\n",
    "    \n",
    "    !plink --bfile {os.path.join(res_folder, adni)} --extract {path} --make-bed --out {os.path.join(res_folder, \"Core\")}\n",
    "    !plink --bfile {os.path.join(res_folder, \"Core\")} --recodeA --out {os.path.join(res_folder, \"Core_recoded\")}\n",
    "    \n",
    "    recoded = pd.read_csv(os.path.join(folder,\"Classification/Classification_2.5/Core_recoded.raw\"),sep=\" \")\n",
    "    recoded = recoded.drop([\"FID\", \"PAT\",\"MAT\",\"SEX\",\"PHENOTYPE\"], axis = 1)\n",
    "\n",
    "    if adni == 'ADNI3':\n",
    "        pheno = pd.read_csv(os.path.join(folder,\"Subjects/Final_Cohort.csv\"),sep=\";\")\n",
    "        pheno = pheno.drop([\"Has genetics?\",\"New subject?\"], axis = 1)\n",
    "\n",
    "        for i in range(pheno.shape[0]):\n",
    "            if(pheno.at[i,'Group'] == 'MCI'):\n",
    "                pheno.at[i,'Group'] = 'AD'\n",
    "        merged = recoded.merge(pheno, on=\"IID\")\n",
    "        data = merged.drop([\"IID\",\"Sex\",\"Group\",\"Age\"], axis = 1) \n",
    "\n",
    "    else:\n",
    "        pheno = pd.read_csv(os.path.join(folder,\"Subjects/Info/\",adni+\"_INFOs.txt\"),sep=\"\\t\")\n",
    "        pheno = pheno.drop([\"RACE\",\"RID\",\"FID\"], axis = 1)\n",
    "\n",
    "        dic = {\n",
    "          1: 'CN',\n",
    "          2: 'AD',\n",
    "          3: 'AD' \n",
    "        }\n",
    "\n",
    "        pheno['CATEGORY'] = pheno['CATEGORY'].map(dic)\n",
    "        pheno.rename(columns={'CATEGORY':'Group'}, inplace=True) \n",
    "        merged = recoded.merge(pheno, on=\"IID\")\n",
    "        data = merged.drop([\"IID\",\"Group\"], axis = 1)\n",
    "\n",
    "\n",
    "    data.fillna(data.median(), inplace=True)\n",
    "    remove = data.columns[data.isna().any()].tolist()\n",
    "    data.drop(remove, axis = 1, inplace=True)\n",
    "    data = data.replace(2,1)\n",
    "   \n",
    "    return data, merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algo(s, X_train, X_test, y_train, y_test, k):\n",
    "    if(s == 'SVM_LINEAR'): clf = svm.SVC(kernel='linear')\n",
    "    elif(s == 'SVM_POLY'): clf = svm.SVC(kernel='poly')\n",
    "    elif(s == 'LDA'):      clf = LDA(n_components=1)\n",
    "    elif(s == 'DT'):       clf = DecisionTreeClassifier()\n",
    "    elif(s == 'KNN'):      clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    else: print('ERROR !!!!')\n",
    "        \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestk(x_train, x_test, y_train, y_test):\n",
    "    k=10\n",
    "    acc_array=np.zeros(k)\n",
    "\n",
    "    for k in np.arange(1,k+1,1): # here k will take values from 1 to 10\n",
    "        classifier = KNeighborsClassifier(n_neighbors=k).fit(x_train, y_train) # k changes after each iteration\n",
    "        y_pred = classifier.predict(x_test)\n",
    "        acc_tmp = metrics.accuracy_score(y_test, y_pred)\n",
    "        acc_array[k-1]=acc_tmp # store correctly the results\n",
    "\n",
    "    max_acc=np.amax(acc_array)\n",
    "    acc_list=list(acc_array)\n",
    "    k = acc_list.index(max_acc)\n",
    "    \n",
    "    return (k+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_results(d_test, d_pred, pos=\"AD\", neg=\"CN\"):\n",
    "    d_test = d_test.tolist()\n",
    "    d_pred = d_pred.tolist()\n",
    "    \n",
    "    tp = tn = fp = fn = 0 \n",
    "    \n",
    "    \n",
    "    for i in range(len(d_test)):\n",
    "        if d_test[i] == pos:\n",
    "            if d_test[i] == d_pred[i]:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        else:\n",
    "            if d_test[i] == d_pred[i]:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "    \n",
    "    if(tp+tn+fp+fn == 0): \n",
    "        accuracy=0\n",
    "    else:\n",
    "        accuracy = (tp + tn) / (tp+tn+fp+fn)\n",
    "        \n",
    "    if(tp + fp == 0):\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = tp / (tp + fp)\n",
    "        \n",
    "    if(tp + fn == 0):\n",
    "        recall = 0\n",
    "    else:\n",
    "         recall = tp / (tp + fn)\n",
    "        \n",
    "    if(precision == recall == 0):\n",
    "        f1score = 0\n",
    "    else:\n",
    "        f1score = 2 * ( (precision*recall) / (precision + recall) )\n",
    "            \n",
    "    \n",
    "    return tp, tn, fp, fn, accuracy, precision, recall, f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: /Users/guglielmo/Desktop/Entropy/DataSet/ADNI3/Classification/Classification_2.5/: File exists\n",
      "PLINK v1.90b6.12 64-bit (28 Oct 2019)          www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2019 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Logging to /Users/guglielmo/Desktop/Entropy/DataSet/ADNI3/Classification/Classification_2.5/Core.log.\n",
      "Options in effect:\n",
      "  --bfile /Users/guglielmo/Desktop/Entropy/DataSet/ADNI3/Classification/Classification_2.5/ADNI3\n",
      "  --extract /Users/guglielmo/Desktop/Entropy/DataSet/ADNI3/Classification/Classification_2.5/snps.txt\n",
      "  --make-bed\n",
      "  --out /Users/guglielmo/Desktop/Entropy/DataSet/ADNI3/Classification/Classification_2.5/Core\n",
      "\n",
      "32768 MB RAM detected; reserving 16384 MB for main workspace.\n",
      "759993 variants loaded from .bim file.\n",
      "327 people (55 males, 84 females, 188 ambiguous) loaded from .fam.\n",
      "Ambiguous sex IDs written to\n",
      "/Users/guglielmo/Desktop/Entropy/DataSet/ADNI3/Classification/Classification_2.5/Core.nosex\n",
      ".\n",
      "--extract: 3564 variants remaining.\n",
      "Warning: At least 11 duplicate IDs in --extract file.\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 327 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Warning: 100 het. haploid genotypes present (see\n",
      "/Users/guglielmo/Desktop/Entropy/DataSet/ADNI3/Classification/Classification_2.5/Core.hh\n",
      "); many commands treat these as missing.\n",
      "Warning: Nonmissing nonmale Y chromosome genotype(s) present; many commands\n",
      "treat these as missing.\n",
      "Total genotyping rate is 0.996142.\n",
      "3564 variants and 327 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "--make-bed to\n",
      "/Users/guglielmo/Desktop/Entropy/DataSet/ADNI3/Classification/Classification_2.5/Core.bed\n",
      "+\n",
      "/Users/guglielmo/Desktop/Entropy/DataSet/ADNI3/Classification/Classification_2.5/Core.bim\n",
      "+\n",
      "/Users/guglielmo/Desktop/Entropy/DataSet/ADNI3/Classification/Classification_2.5/Core.fam\n",
      "... 101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899done.\n",
      "PLINK v1.90b6.12 64-bit (28 Oct 2019)          www.cog-genomics.org/plink/1.9/\n",
      "(C) 2005-2019 Shaun Purcell, Christopher Chang   GNU General Public License v3\n",
      "Note: --recodeA flag deprecated.  Use \"--recode A ...\".\n",
      "Logging to /Users/guglielmo/Desktop/Entropy/DataSet/ADNI3/Classification/Classification_2.5/Core_recoded.log.\n",
      "Options in effect:\n",
      "  --bfile /Users/guglielmo/Desktop/Entropy/DataSet/ADNI3/Classification/Classification_2.5/Core\n",
      "  --out /Users/guglielmo/Desktop/Entropy/DataSet/ADNI3/Classification/Classification_2.5/Core_recoded\n",
      "  --recode A\n",
      "\n",
      "32768 MB RAM detected; reserving 16384 MB for main workspace.\n",
      "3564 variants loaded from .bim file.\n",
      "327 people (55 males, 84 females, 188 ambiguous) loaded from .fam.\n",
      "Ambiguous sex IDs written to\n",
      "/Users/guglielmo/Desktop/Entropy/DataSet/ADNI3/Classification/Classification_2.5/Core_recoded.nosex\n",
      ".\n",
      "Using 1 thread (no multithreaded calculations invoked).\n",
      "Before main variant filters, 327 founders and 0 nonfounders present.\n",
      "Calculating allele frequencies... 10111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989 done.\n",
      "Warning: 100 het. haploid genotypes present (see\n",
      "/Users/guglielmo/Desktop/Entropy/DataSet/ADNI3/Classification/Classification_2.5/Core_recoded.hh\n",
      "); many commands treat these as missing.\n",
      "Warning: Nonmissing nonmale Y chromosome genotype(s) present; many commands\n",
      "treat these as missing.\n",
      "Total genotyping rate is 0.996142.\n",
      "3564 variants and 327 people pass filters and QC.\n",
      "Note: No phenotypes present.\n",
      "--recode A to\n",
      "/Users/guglielmo/Desktop/Entropy/DataSet/ADNI3/Classification/Classification_2.5/Core_recoded.raw\n",
      "... 101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899done.\n",
      "\u001b[1m\u001b[94m$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$  ADNI3  $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[92m###############################################  METHOD: SVM_LINEAR  ###############################################\u001b[0m\n",
      "****CN****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.9158 0.0229 - F1: 0.945 0.0146 - Precision: 0.9259 0.0255 - Recall: 0.9656 0.0199\n",
      "\n",
      "****AD****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.9158 0.0229 - F1: 0.8201 0.0552 - Precision: 0.8873 0.0587 - Recall: 0.7687 0.0865\n",
      "\n",
      "****Confusion Matrix****\n",
      "# AD CN All\n",
      "AD 17.68(1.989) 5.32(1.989) 23(0.0) \n",
      "CN 2.34(1.35) 65.66(1.35) 68(0.0) \n",
      "All 20.02(2.685) 70.98(2.685) 91(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "****CN****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.9306 0.0441 - F1: 0.9541 0.029 - Precision: 0.9412 0.0405 - Recall: 0.9687 0.0345\n",
      "\n",
      "****AD****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.9306 0.0441 - F1: 0.8564 0.0943 - Precision: 0.9084 0.0967 - Recall: 0.8213 0.1284\n",
      "\n",
      "****Confusion Matrix****\n",
      "# AD CN All\n",
      "AD 6.57(1.027) 1.43(1.027) 8(0.0) \n",
      "CN 0.72(0.792) 22.28(0.792) 23(0.0) \n",
      "All 7.29(1.225) 23.71(1.225) 31(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m\u001b[92m###############################################  METHOD: SVM_POLY  ###############################################\u001b[0m\n",
      "****CN****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.784 0.0196 - F1: 0.8734 0.0103 - Precision: 0.7777 0.0157 - Recall: 0.9962 0.0065\n",
      "\n",
      "****AD****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.784 0.0196 - F1: 0.2607 0.1136 - Precision: 0.9178 0.1758 - Recall: 0.1565 0.0764\n",
      "\n",
      "****Confusion Matrix****\n",
      "# AD CN All\n",
      "AD 3.673(1.698) 19.4(1.758) 23(0.0) \n",
      "CN 0.265(0.444) 67.74(0.441) 68(0.0) \n",
      "All 3.939(1.769) 87.14(1.837) 91(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "****CN****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.8355 0.0401 - F1: 0.9001 0.0224 - Precision: 0.8236 0.0367 - Recall: 0.9935 0.0156\n",
      "\n",
      "****AD****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.8355 0.0401 - F1: 0.5267 0.1669 - Precision: 0.9528 0.1348 - Recall: 0.3812 0.1542\n",
      "\n",
      "****Confusion Matrix****\n",
      "# AD CN All\n",
      "AD 3.081(1.201) 4.95(1.234) 8(0.0) \n",
      "CN 0.152(0.36) 22.85(0.359) 23(0.0) \n",
      "All 3.232(1.292) 27.8(1.326) 31(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m\u001b[92m###############################################  METHOD: LDA  ###############################################\u001b[0m\n",
      "****CN****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.822 0.0339 - F1: 0.8871 0.0205 - Precision: 0.8468 0.0402 - Recall: 0.9344 0.041\n",
      "\n",
      "****AD****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.822 0.0339 - F1: 0.5655 0.1304 - Precision: 0.7353 0.1123 - Recall: 0.4896 0.1686\n",
      "\n",
      "****Confusion Matrix****\n",
      "# AD CN All\n",
      "AD 11.26(3.879) 11.74(3.879) 23(0.0) \n",
      "CN 4.46(2.79) 63.54(2.79) 68(0.0) \n",
      "All 15.72(6.012) 75.28(6.012) 91(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "****CN****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.8297 0.0539 - F1: 0.8862 0.0369 - Precision: 0.88 0.0519 - Recall: 0.8974 0.0656\n",
      "\n",
      "****AD****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.8297 0.0539 - F1: 0.6491 0.1279 - Precision: 0.706 0.1461 - Recall: 0.635 0.1818\n",
      "\n",
      "****Confusion Matrix****\n",
      "# AD CN All\n",
      "AD 5.08(1.454) 2.92(1.454) 8(0.0) \n",
      "CN 2.36(1.508) 20.64(1.508) 23(0.0) \n",
      "All 7.44(2.447) 23.56(2.447) 31(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m\u001b[92m###############################################  METHOD: DT  ###############################################\u001b[0m\n",
      "****CN****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.6623 0.0449 - F1: 0.7744 0.0342 - Precision: 0.7719 0.0274 - Recall: 0.7787 0.0541\n",
      "\n",
      "****AD****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.6623 0.0449 - F1: 0.3194 0.0896 - Precision: 0.3274 0.0899 - Recall: 0.3183 0.1013\n",
      "\n",
      "****Confusion Matrix****\n",
      "# AD CN All\n",
      "AD 7.32(2.331) 15.68(2.331) 23(0.0) \n",
      "CN 15.05(3.677) 52.95(3.677) 68(0.0) \n",
      "All 22.37(4.607) 68.63(4.607) 91(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****CN****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.6519 0.0777 - F1: 0.7668 0.0595 - Precision: 0.7586 0.0475 - Recall: 0.7796 0.0909\n",
      "\n",
      "****AD****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.6519 0.0777 - F1: 0.2884 0.1512 - Precision: 0.3077 0.1615 - Recall: 0.285 0.1619\n",
      "\n",
      "****Confusion Matrix****\n",
      "# AD CN All\n",
      "AD 2.28(1.296) 5.72(1.296) 8(0.0) \n",
      "CN 5.07(2.09) 17.93(2.09) 23(0.0) \n",
      "All 7.35(2.508) 23.65(2.508) 31(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "\u001b[1m\u001b[92m###############################################  METHOD: KNN  ###############################################\u001b[0m\n",
      "****CN****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.8423 0.03 - F1: 0.8993 0.0188 - Precision: 0.8612 0.0284 - Recall: 0.9422 0.0297\n",
      "\n",
      "****AD****\n",
      "\u001b[1m\u001b[93mTrain 70.0%- Test 30.0%\u001b[0m - Accuracy: 0.8423 0.03 - F1: 0.6324 0.0841 - Precision: 0.7701 0.0912 - Recall: 0.547 0.1087\n",
      "\n",
      "****Confusion Matrix****\n",
      "# AD CN All\n",
      "AD 12.58(2.499) 10.42(2.499) 23(0.0) \n",
      "CN 3.93(2.016) 64.07(2.016) 68(0.0) \n",
      "All 16.51(3.631) 74.49(3.631) 91(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n",
      "****CN****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.8348 0.061 - F1: 0.8926 0.0394 - Precision: 0.8667 0.0543 - Recall: 0.923 0.0524\n",
      "\n",
      "****AD****\n",
      "\u001b[1m\u001b[93mTrain 90.0%- Test 10.0%\u001b[0m - Accuracy: 0.8348 0.061 - F1: 0.6348 0.1502 - Precision: 0.7366 0.1611 - Recall: 0.5813 0.1867\n",
      "\n",
      "****Confusion Matrix****\n",
      "# AD CN All\n",
      "AD 4.65(1.493) 3.35(1.493) 8(0.0) \n",
      "CN 1.77(1.205) 21.23(1.205) 23(0.0) \n",
      "All 6.42(1.945) 24.58(1.945) 31(0.0) \n",
      "-------------------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for adni in ['ADNI3']:#['ADNI1','ADNI2_GO','ADNI3']:\n",
    "    [data, merged] = getData(adni)\n",
    "    column_names   = [\"Method\", \"Accuracy\", \"F1\", \"Precision\", \"Recall\", \"TrainSize\"]\n",
    "    df = pd.DataFrame(columns = column_names)\n",
    "    print(bcolors.BOLD + bcolors.OKBLUE +'$' * 52 + '  ' +  adni + '  ' + '$' * 52 + bcolors.ENDC)\n",
    "    print()\n",
    "    for method in ['SVM_LINEAR','SVM_POLY','LDA','DT','KNN']: \n",
    "        print(bcolors.BOLD + bcolors.OKGREEN + '#' * 47 + \"  METHOD: \" + method + '  ' + '#' * 47 + bcolors.ENDC)\n",
    "        for s in [0.3, 0.1]:\n",
    "            acc = list()\n",
    "            f1  = list()\n",
    "            precision = list()\n",
    "            recall    = list()\n",
    "\n",
    "            v_acc = list()\n",
    "            v_f1  = list()\n",
    "            v_precision = list()\n",
    "            v_recall    = list()\n",
    "\n",
    "            v_acc_cn = list()\n",
    "            v_f1_cn  = list()\n",
    "            v_precision_cn = list()\n",
    "            v_recall_cn    = list()\n",
    "\n",
    "            conf_mat = dict()\n",
    "            \n",
    "            flag = True \n",
    "            k = 5\n",
    "            \n",
    "            for i in range(1, 101):\n",
    "                rand = i \n",
    "                X_train, X_test, y_train, y_test = train_test_split(data, merged['Group'], test_size=s, \n",
    "                                                                    random_state=rand, stratify=merged['Group'])\n",
    "                if(method=='KNN' and flag):\n",
    "                        k = bestk(X_train, X_test, y_train, y_test)\n",
    "                        flag = False\n",
    "                \n",
    "                clf = algo(method, X_train, X_test, y_train, y_test, k)\n",
    "                clf.fit(X_train, y_train)\n",
    "                y_pred = clf.predict(X_test)\n",
    "\n",
    "                dd_pred = [ 0 if x == 'CN' else 1 for x in y_pred.tolist()]\n",
    "                dd_test = [ 0 if x == 'CN' else 1 for x in y_test.tolist()]\n",
    "\n",
    "                acc.append(metrics.accuracy_score(dd_test, dd_pred))\n",
    "                f1.append(metrics.f1_score(dd_test, dd_pred))\n",
    "                precision.append(metrics.precision_score(dd_test, dd_pred))\n",
    "                recall.append(metrics.recall_score(dd_test, dd_pred))\n",
    "\n",
    "\n",
    "                v_tp, v_tn, v_fp, v_fn, v_a, v_p, v_r, v_f = classification_results(y_test, y_pred)\n",
    "                v_acc.append(v_a)\n",
    "                v_f1.append(v_f)\n",
    "                v_precision.append(v_p)\n",
    "                v_recall.append(v_r)\n",
    "\n",
    "                v_tp, v_tn, v_fp, v_fn, v_a, v_p, v_r, v_f = classification_results(y_test,y_pred, pos='CN', neg='AD')\n",
    "                v_acc_cn.append(v_a)\n",
    "                v_f1_cn.append(v_f)\n",
    "                v_precision_cn.append(v_p)\n",
    "                v_recall_cn.append(v_r)\n",
    "                \n",
    "                df_confusion = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "                for c in df_confusion.columns:\n",
    "                    for r in df_confusion.index:\n",
    "                        cr = (c,r)\n",
    "                        if cr not in conf_mat:\n",
    "                            conf_mat[cr] = list()\n",
    "                        conf_mat[cr].append( int(df_confusion.at[r,c]) )\n",
    "            \n",
    "            print(\"****CN****\")\n",
    "            print(bcolors.BOLD + bcolors.WARNING +\"Train \"+ str((1-s)*100) + \"%\" +\"- Test \" + str(s*100) + \"%\" +bcolors.ENDC +\n",
    "                  \" - Accuracy: \"  + str(round(statistics.mean(v_acc_cn), 4)) +\" \"+str(round(statistics.stdev(v_acc_cn), 4))+\n",
    "                  \" - F1: \"        + str(round(statistics.mean(v_f1_cn), 4)) + \" \"+str(round(statistics.stdev(v_f1_cn), 4))+\n",
    "                  \" - Precision: \" + str(round(statistics.mean(v_precision_cn), 4)) + \" \"+str(round(statistics.stdev(v_precision_cn), 4))+\n",
    "                  \" - Recall: \"    + str(round(statistics.mean(v_recall_cn), 4)) +\" \"+str(round(statistics.stdev(v_recall_cn), 4)))\n",
    "            print()\n",
    "\n",
    "            print(\"****AD****\")\n",
    "            print(bcolors.BOLD + bcolors.WARNING +\"Train \"+ str((1-s)*100) + \"%\" +\"- Test \" + str(s*100) + \"%\" +bcolors.ENDC +\n",
    "                  \" - Accuracy: \"  + str(round(statistics.mean(v_acc), 4)) + \" \"+str(round(statistics.stdev(v_acc), 4))+\n",
    "                  \" - F1: \"        + str(round(statistics.mean(v_f1), 4)) + \" \"+str(round(statistics.stdev(v_f1), 4))+\n",
    "                  \" - Precision: \" + str(round(statistics.mean(v_precision), 4)) + \" \"+str(round(statistics.stdev(v_precision), 4))+\n",
    "                  \" - Recall: \"    + str(round(statistics.mean(v_recall), 4)) +\" \"+str(round(statistics.stdev(v_recall), 4)))\n",
    "            print()\n",
    "            \n",
    "            '''\n",
    "            print(\"****MEAN(AD,CN)****\")\n",
    "            print(\"Train \"+ str((1-s)*100) + \"%\" +\" - Test \" + str(s*100) + \"%\" + \n",
    "                  \" - V Accuracy: \"  + str(round(statistics.mean([statistics.mean(v_acc),statistics.mean(v_acc_cn)]), 4)) +\n",
    "                  \" - V F1: \"        + str(round(statistics.mean([statistics.mean(v_f1),statistics.mean(v_f1_cn)]), 4)) +\n",
    "                  \" - V Precision: \" + str(round(statistics.mean([statistics.mean(v_precision),statistics.mean(v_precision_cn)]), 4)) +\n",
    "                  \" - V Recall: \"    + str(round(statistics.mean([statistics.mean(v_recall),statistics.mean(v_recall_cn)]), 4)))\n",
    "            print()\n",
    "            '''\n",
    "            \n",
    "            print(\"****Confusion Matrix****\")\n",
    "            print(\"# \"+ \" \".join(list(df_confusion.columns)))\n",
    "\n",
    "            for r in df_confusion.index:\n",
    "                print(r+\" \",end=\"\")\n",
    "                for c in df_confusion.columns:\n",
    "                    print( str(round(statistics.mean(conf_mat[(c,r)]),3)) + \n",
    "                          \"(\" + str(round(statistics.stdev(conf_mat[(c,r)]),3)) + \") \" , end=\"\" )\n",
    "                print()\n",
    "            print('-' * 115)\n",
    "            \n",
    "            \n",
    "            acc_plot = round(statistics.mean([statistics.mean(v_acc),statistics.mean(v_acc_cn)]), 4)\n",
    "            f1_plot  = round(statistics.mean([statistics.mean(v_f1),statistics.mean(v_f1_cn)]), 4)\n",
    "            precision_plot = round(statistics.mean([statistics.mean(v_precision),statistics.mean(v_precision_cn)]), 4)\n",
    "            recall_plot = round(statistics.mean([statistics.mean(v_recall),statistics.mean(v_recall_cn)]), 4)\n",
    "            \n",
    "            df = df.append({\"Method\":method, \"Accuracy\":acc_plot, \"F1\":f1_plot, \"Precision\":precision_plot, \n",
    "                            \"Recall\":recall_plot, \"TrainSize\":int((1-s)*100)}, ignore_index=True)\n",
    "            \n",
    "    df.to_csv(\"../PLOT/\"+adni+\"_res.csv\", header=True, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
